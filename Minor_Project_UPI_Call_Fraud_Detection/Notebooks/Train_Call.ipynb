{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ec0edec9-3e3c-4cfd-8d96-e0af928ec895",
   "metadata": {},
   "source": [
    "### Imporing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "51ce0789-2da1-476f-a859-1cf2a8c96391",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Environment ready for CDR ensemble training (warnings suppressed).\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# Config\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")  #\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"3\" \n",
    "\n",
    "\n",
    "\n",
    "print(\"Environment ready for CDR ensemble training (warnings suppressed).\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6716d19f-e4da-4c68-92ad-01a1a4cae4dc",
   "metadata": {},
   "source": [
    "### Load & Prepare Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e12910c7-b58f-4c2c-9a41-a28e8e159e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded and balanced:\n",
      "Train shape: (49429, 11) | Test shape: (10000, 11)\n",
      "Fraud ratio: 0.2308\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../dataset/CDR_Dataset.csv\"\n",
    "df = pd.read_csv(data_path, parse_dates=[\"call_start_time\"])\n",
    "\n",
    "# Convert label column\n",
    "df[\"label\"] = df[\"label\"].map({\"Fraud\": 1, \"Not Fraud\": 0})\n",
    "\n",
    "# Drop irrelevant IDs and convert to numeric\n",
    "drop_cols = [\"call_id\", \"caller_id\", \"callee_id\", \"imei\", \"imsi\", \"cell_tower_id\", \"call_start_time\"]\n",
    "X = df.drop(columns=drop_cols + [\"label\"], errors=\"ignore\")\n",
    "y = df[\"label\"]\n",
    "\n",
    "# One-hot encode call_type if present\n",
    "if \"call_type\" in X.columns:\n",
    "    X = pd.get_dummies(X, columns=[\"call_type\"], prefix=\"type\")\n",
    "\n",
    "# Fill missing values\n",
    "X = X.fillna(0)\n",
    "\n",
    "# Train-test split + SMOTE\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "sm = SMOTE(random_state=RANDOM_STATE, sampling_strategy=0.3)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Data loaded and balanced:\")\n",
    "print(\"Train shape:\", X_train_res.shape, \"| Test shape:\", X_test.shape)\n",
    "print(\"Fraud ratio:\", y_train_res.mean().round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "908c03dd-588a-4768-9844-e2bf4098a70e",
   "metadata": {},
   "source": [
    "### Training Supervised Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9dcc073-1475-4a1a-8b66-0ada9c5d9483",
   "metadata": {},
   "source": [
    "### 1. XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b6633ed-62ca-411f-aaf1-de2c8575c55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(\n",
    "    colsample_bytree=0.8,\n",
    "    learning_rate=0.2,\n",
    "    max_depth=4,\n",
    "    n_estimators=200,\n",
    "    subsample=1.0,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    use_label_encoder=False,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a884506-6ba4-4df6-9a62-7db9192d5b51",
   "metadata": {},
   "source": [
    "### 2. RandomForest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5cda550a-919a-453b-a97c-80a68f73430f",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=10,\n",
    "    n_estimators=200,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d03911bc-e6d2-43d0-ab84-aa637086c96e",
   "metadata": {},
   "source": [
    "### 3.  Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ac7ae0fb-cb27-491f-a269-7d530b0c612c",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9eafa1-7d10-45b5-b826-18cb19f031cb",
   "metadata": {},
   "source": [
    "### Fittng Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0c3edf0e-3286-417f-975e-d6553fb56ae9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Supervised models trained successfully.\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(X_train_res, y_train_res)\n",
    "rf.fit(X_train_res, y_train_res)\n",
    "lr_model.fit(X_train_scaled, y_train_res)\n",
    "print(\" Supervised models trained successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23321568-af15-4dd0-a0bb-8fab47f4dc03",
   "metadata": {},
   "source": [
    "### Evaluating Supervised Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b041d551-1444-4fe7-8b7b-02935e932a56",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ XGBoost ROC-AUC: 0.9944\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9963    0.9975    0.9969      9506\n",
      "           1     0.9503    0.9291    0.9396       494\n",
      "\n",
      "    accuracy                         0.9941     10000\n",
      "   macro avg     0.9733    0.9633    0.9683     10000\n",
      "weighted avg     0.9940    0.9941    0.9941     10000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[9482   24]\n",
      " [  35  459]]\n",
      "\n",
      "ðŸ”¹ RandomForest ROC-AUC: 0.9947\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9966    0.9943    0.9955      9506\n",
      "           1     0.8953    0.9352    0.9149       494\n",
      "\n",
      "    accuracy                         0.9914     10000\n",
      "   macro avg     0.9460    0.9648    0.9552     10000\n",
      "weighted avg     0.9916    0.9914    0.9915     10000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[9452   54]\n",
      " [  32  462]]\n",
      "\n",
      "ðŸ”¹ LogisticRegression ROC-AUC: 0.9275\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9901    0.9648    0.9772      9506\n",
      "           1     0.5455    0.8138    0.6531       494\n",
      "\n",
      "    accuracy                         0.9573     10000\n",
      "   macro avg     0.7678    0.8893    0.8152     10000\n",
      "weighted avg     0.9681    0.9573    0.9612     10000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[9171  335]\n",
      " [  92  402]]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X, y, name, scaled=False):\n",
    "    preds = model.predict_proba(X)[:, 1]\n",
    "    auc = roc_auc_score(y, preds)\n",
    "    print(f\"\\nðŸ”¹ {name} ROC-AUC: {auc:.4f}\")\n",
    "    print(classification_report(y, preds > 0.5, digits=4))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y, preds > 0.5))\n",
    "    return preds\n",
    "\n",
    "p_xgb = evaluate_model(xgb, X_test, y_test, \"XGBoost\")\n",
    "p_rf = evaluate_model(rf, X_test, y_test, \"RandomForest\")\n",
    "p_lr = evaluate_model(lr_model, X_test_scaled, y_test, \"LogisticRegression\", scaled=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "353efffc-036f-408d-a67a-dd599f9022f2",
   "metadata": {},
   "source": [
    "### Training Unsupervised Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6e2aba-5c95-44b1-8057-8e0c502fb6cc",
   "metadata": {},
   "source": [
    "### 1. Isolation Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "024fd217-5547-4de6-abb3-3f2abb291aaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsolationForest trained and anomaly scores normalized.\n"
     ]
    }
   ],
   "source": [
    "iso_train = X_train[y_train == 0]  # Only normal calls\n",
    "iso_model = IsolationForest(contamination=0.02, random_state=RANDOM_STATE)\n",
    "iso_model.fit(iso_train)\n",
    "\n",
    "# Get anomaly scores (negative = anomaly)\n",
    "s_iso = -iso_model.score_samples(X_test)\n",
    "scaler_iso = MinMaxScaler()\n",
    "p_iso = scaler_iso.fit_transform(s_iso.reshape(-1, 1)).ravel()\n",
    "\n",
    "print(\"IsolationForest trained and anomaly scores normalized.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1959522-ae12-48fb-9825-46e60a651642",
   "metadata": {},
   "source": [
    "### 2. Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ae3cbd6a-8fc3-4807-b5c0-c5b96231fdac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Autoencoder trained and reconstruction errors normalized.\n"
     ]
    }
   ],
   "source": [
    "X_train_clean = X_train.select_dtypes(include=[np.number]).fillna(0)\n",
    "X_test_clean = X_test.select_dtypes(include=[np.number]).fillna(0)\n",
    "\n",
    "ae_train = X_train_clean[y_train == 0].values.astype(\"float32\")\n",
    "input_dim = ae_train.shape[1]\n",
    "encoding_dim = int(input_dim / 2)\n",
    "\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
    "decoder = Dense(input_dim, activation=\"sigmoid\")(encoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")\n",
    "autoencoder.fit(ae_train, ae_train, epochs=10, batch_size=256, shuffle=True, verbose=0)\n",
    "\n",
    "X_test_np = X_test_clean.values.astype(\"float32\")\n",
    "reconstructions = autoencoder.predict(X_test_np, verbose=0)\n",
    "reconstruction_error = np.mean(np.square(X_test_np - reconstructions), axis=1)\n",
    "\n",
    "scaler_ae = MinMaxScaler()\n",
    "p_ae = scaler_ae.fit_transform(reconstruction_error.reshape(-1, 1)).ravel()\n",
    "\n",
    "print(\"Autoencoder trained and reconstruction errors normalized.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd96429b-cb50-4947-b8d2-ed43a53b7ef6",
   "metadata": {},
   "source": [
    "### Combine Ensemble Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "66793463-a372-42c8-8aad-2a073e21c8c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined ensemble scores computed.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_xgb</th>\n",
       "      <th>p_rf</th>\n",
       "      <th>p_lr</th>\n",
       "      <th>p_iso</th>\n",
       "      <th>p_ae</th>\n",
       "      <th>label</th>\n",
       "      <th>p_sup</th>\n",
       "      <th>p_unsup</th>\n",
       "      <th>p_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.000024</td>\n",
       "      <td>0.021229</td>\n",
       "      <td>0.151931</td>\n",
       "      <td>0.101352</td>\n",
       "      <td>0.000143</td>\n",
       "      <td>0</td>\n",
       "      <td>0.057728</td>\n",
       "      <td>0.050748</td>\n",
       "      <td>0.055634</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.000001</td>\n",
       "      <td>0.001276</td>\n",
       "      <td>0.174230</td>\n",
       "      <td>0.083388</td>\n",
       "      <td>0.001150</td>\n",
       "      <td>0</td>\n",
       "      <td>0.058502</td>\n",
       "      <td>0.042269</td>\n",
       "      <td>0.053632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.000094</td>\n",
       "      <td>0.012445</td>\n",
       "      <td>0.127224</td>\n",
       "      <td>0.091309</td>\n",
       "      <td>0.000097</td>\n",
       "      <td>0</td>\n",
       "      <td>0.046588</td>\n",
       "      <td>0.045703</td>\n",
       "      <td>0.046322</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.000003</td>\n",
       "      <td>0.001602</td>\n",
       "      <td>0.148108</td>\n",
       "      <td>0.137375</td>\n",
       "      <td>0.000647</td>\n",
       "      <td>0</td>\n",
       "      <td>0.049904</td>\n",
       "      <td>0.069011</td>\n",
       "      <td>0.055636</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002255</td>\n",
       "      <td>0.015044</td>\n",
       "      <td>0.063060</td>\n",
       "      <td>0.444000</td>\n",
       "      <td>0.000043</td>\n",
       "      <td>0</td>\n",
       "      <td>0.026786</td>\n",
       "      <td>0.222021</td>\n",
       "      <td>0.085357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      p_xgb      p_rf      p_lr     p_iso      p_ae  label     p_sup  \\\n",
       "0  0.000024  0.021229  0.151931  0.101352  0.000143      0  0.057728   \n",
       "1  0.000001  0.001276  0.174230  0.083388  0.001150      0  0.058502   \n",
       "2  0.000094  0.012445  0.127224  0.091309  0.000097      0  0.046588   \n",
       "3  0.000003  0.001602  0.148108  0.137375  0.000647      0  0.049904   \n",
       "4  0.002255  0.015044  0.063060  0.444000  0.000043      0  0.026786   \n",
       "\n",
       "    p_unsup   p_final  \n",
       "0  0.050748  0.055634  \n",
       "1  0.042269  0.053632  \n",
       "2  0.045703  0.046322  \n",
       "3  0.069011  0.055636  \n",
       "4  0.222021  0.085357  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    \"p_xgb\": p_xgb,\n",
    "    \"p_rf\": p_rf,\n",
    "    \"p_lr\": p_lr,\n",
    "    \"p_iso\": p_iso,\n",
    "    \"p_ae\": p_ae,\n",
    "    \"label\": y_test.values\n",
    "})\n",
    "\n",
    "results_df[\"p_sup\"] = results_df[[\"p_xgb\", \"p_rf\", \"p_lr\"]].mean(axis=1)\n",
    "results_df[\"p_unsup\"] = results_df[[\"p_iso\", \"p_ae\"]].mean(axis=1)\n",
    "results_df[\"p_final\"] = (0.7 * results_df[\"p_sup\"]) + (0.3 * results_df[\"p_unsup\"])\n",
    "\n",
    "print(\"Combined ensemble scores computed.\")\n",
    "results_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ecc7435-69e2-4c96-bea4-adae4153817a",
   "metadata": {},
   "source": [
    "### Risk Buckets "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "cf72445e-08f5-456b-b6b7-175a42d9698f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Risk buckets assigned:\n",
      "risk_bucket\n",
      "Low       9431\n",
      "High       395\n",
      "Medium     174\n",
      "Name: count, dtype: int64\n",
      "\n",
      " Final Ensemble ROC-AUC: 0.9878\n"
     ]
    }
   ],
   "source": [
    "def risk_bucket(p):\n",
    "    if p >= 0.7:\n",
    "        return \"High\"\n",
    "    elif p >= 0.3:\n",
    "        return \"Medium\"\n",
    "    return \"Low\"\n",
    "\n",
    "results_df[\"risk_bucket\"] = results_df[\"p_final\"].apply(risk_bucket)\n",
    "print(\" Risk buckets assigned:\")\n",
    "print(results_df[\"risk_bucket\"].value_counts())\n",
    "\n",
    "roc_final = roc_auc_score(results_df[\"label\"], results_df[\"p_final\"])\n",
    "print(f\"\\n Final Ensemble ROC-AUC: {roc_final:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c38f135d-215d-4a57-9fc0-3f4ede75c13f",
   "metadata": {},
   "source": [
    "### Saving Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a668051-dc1d-4d27-858a-22070e1d8d6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " All models and predictions saved successfully to: ../models/cdr_ensemble\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"../models/cdr_ensemble\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "joblib.dump(xgb, f\"{model_dir}/cdr_xgb.joblib\")\n",
    "joblib.dump(rf, f\"{model_dir}/cdr_rf.joblib\")\n",
    "joblib.dump(lr_model, f\"{model_dir}/cdr_lr.joblib\")\n",
    "joblib.dump(iso_model, f\"{model_dir}/cdr_iso.joblib\")\n",
    "autoencoder.save(f\"{model_dir}/cdr_autoencoder.keras\")\n",
    "joblib.dump(scaler, f\"{model_dir}/scaler_lr.joblib\")\n",
    "joblib.dump(scaler_iso, f\"{model_dir}/scaler_iso.joblib\")\n",
    "joblib.dump(scaler_ae, f\"{model_dir}/scaler_ae.joblib\")\n",
    "\n",
    "results_path = \"../dataset/cdr_ensemble_predictions.csv\"\n",
    "results_df.to_csv(results_path, index=False)\n",
    "\n",
    "print(f\" All models and predictions saved successfully to: {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be536a0b-42b6-4023-991a-3cb53d2dacc7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
