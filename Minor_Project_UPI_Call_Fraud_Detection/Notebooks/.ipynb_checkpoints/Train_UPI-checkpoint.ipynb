{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b3d1caef-aa48-49fc-99fe-9a57997853ca",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2ac670ea-1c35-4f03-b8ce-510c0ce74ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import joblib\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler\n",
    "from sklearn.metrics import roc_auc_score, classification_report, confusion_matrix\n",
    "from sklearn.ensemble import RandomForestClassifier, IsolationForest\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "# Config\n",
    "RANDOM_STATE = 42\n",
    "np.random.seed(RANDOM_STATE)\n",
    "tf.random.set_seed(RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11700242-a3ee-4fdd-9398-40c04bc2e57a",
   "metadata": {},
   "source": [
    "### Loading Dataset, Feature and targets and Train-Test Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8c479b4b-228e-438d-8784-05da6fd78dbd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\envs\\tf_env\\lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "C:\\Users\\Lenovo\\anaconda3\\envs\\tf_env\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py:136: UserWarning: Could not find the number of physical cores for the following reason:\n",
      "[WinError 2] The system cannot find the file specified\n",
      "Returning the number of logical cores instead. You can silence this warning by setting LOKY_MAX_CPU_COUNT to the number of cores you want to use.\n",
      "  warnings.warn(\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\envs\\tf_env\\lib\\site-packages\\joblib\\externals\\loky\\backend\\context.py\", line 257, in _count_physical_cores\n",
      "    cpu_info = subprocess.run(\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\envs\\tf_env\\lib\\subprocess.py\", line 505, in run\n",
      "    with Popen(*popenargs, **kwargs) as process:\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\envs\\tf_env\\lib\\subprocess.py\", line 951, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"C:\\Users\\Lenovo\\anaconda3\\envs\\tf_env\\lib\\subprocess.py\", line 1420, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (95459, 44) | Test: (20000, 44)\n",
      "Fraud Ratio (Train): 0.2308\n"
     ]
    }
   ],
   "source": [
    "data_path = \"../dataset/paysim_feature_engineered.csv\"\n",
    "df = pd.read_csv(data_path)\n",
    "\n",
    "target_col = \"isFraud\"\n",
    "y = df[target_col]\n",
    "X = df.drop(columns=[\"isFraud\", \"isFlaggedFraud\", \"nameOrig\", \"nameDest\", \"step\", \"type\"], errors=\"ignore\").fillna(0)\n",
    "\n",
    "# Split and SMOTE\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, stratify=y, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "sm = SMOTE(random_state=RANDOM_STATE, sampling_strategy=0.3)\n",
    "X_train_res, y_train_res = sm.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Train:\", X_train_res.shape, \"| Test:\", X_test.shape)\n",
    "print(\"Fraud Ratio (Train):\", y_train_res.mean().round(4))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5849dbb0-a366-455c-b578-a341eef793b9",
   "metadata": {},
   "source": [
    "### Train Supervised Models "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "813ab90d-1a03-41a1-a194-4e48acd21275",
   "metadata": {},
   "source": [
    "### XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "938bacdc-52c6-44a8-8f9b-c1af98be42b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(\n",
    "    colsample_bytree=0.8,\n",
    "    learning_rate=0.2,\n",
    "    max_depth=4,\n",
    "    n_estimators=200,\n",
    "    subsample=1.0,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    use_label_encoder=False,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60dedc0a-65a5-462c-afb2-0c59bcb4b3f7",
   "metadata": {},
   "source": [
    "### RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26b9eaa5-ca57-425a-a2d4-67d194de42ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(\n",
    "    max_depth=10,\n",
    "    min_samples_leaf=2,\n",
    "    min_samples_split=10,\n",
    "    n_estimators=200,\n",
    "    class_weight=\"balanced\",\n",
    "    random_state=RANDOM_STATE,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2acbc7b4-da70-4f1c-9837-a076b479ba90",
   "metadata": {},
   "source": [
    "### Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5fcf531c-aef1-4780-b46c-0ed7c9930446",
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_res)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "lr_model = LogisticRegression(max_iter=1000, class_weight=\"balanced\", random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7c03fcd-cd61-44e8-9d7f-1aef73f2adf7",
   "metadata": {},
   "source": [
    "### Fit Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "476e861d-fe5b-4556-a6e1-2e8fe06c133e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Lenovo\\anaconda3\\envs\\tf_env\\lib\\site-packages\\xgboost\\core.py:158: UserWarning: [20:07:33] WARNING: C:\\buildkite-agent\\builds\\buildkite-windows-cpu-autoscaling-group-i-08cbc0333d8d4aae1-1\\xgboost\\xgboost-ci-windows\\src\\learner.cc:740: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  warnings.warn(smsg, UserWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " All supervised models trained successfully.\n"
     ]
    }
   ],
   "source": [
    "xgb.fit(X_train_res, y_train_res)\n",
    "rf.fit(X_train_res, y_train_res)     # â† Added this line (the fix)\n",
    "lr_model.fit(X_train_scaled, y_train_res)\n",
    "\n",
    "print(\" All supervised models trained successfully.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8f9fbc-6979-4db3-8aac-8594438714d1",
   "metadata": {},
   "source": [
    "### Evaluate Supervised Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1eca6494-cb43-4fd4-ba56-e58a4d343b89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ðŸ”¹ XGBoost ROC-AUC: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9999    0.9999    0.9999     18357\n",
      "           1     0.9994    0.9994    0.9994      1643\n",
      "\n",
      "    accuracy                         0.9999     20000\n",
      "   macro avg     0.9997    0.9997    0.9997     20000\n",
      "weighted avg     0.9999    0.9999    0.9999     20000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[18356     1]\n",
      " [    1  1642]]\n",
      "\n",
      "ðŸ”¹ RandomForest ROC-AUC: 1.0000\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9999    1.0000    1.0000     18357\n",
      "           1     1.0000    0.9994    0.9997      1643\n",
      "\n",
      "    accuracy                         1.0000     20000\n",
      "   macro avg     1.0000    0.9997    0.9998     20000\n",
      "weighted avg     1.0000    1.0000    0.9999     20000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[18357     0]\n",
      " [    1  1642]]\n",
      "\n",
      "ðŸ”¹ LogisticRegression ROC-AUC: 0.9980\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9988    0.9792    0.9889     18357\n",
      "           1     0.8098    0.9872    0.8897      1643\n",
      "\n",
      "    accuracy                         0.9799     20000\n",
      "   macro avg     0.9043    0.9832    0.9393     20000\n",
      "weighted avg     0.9833    0.9799    0.9808     20000\n",
      "\n",
      "Confusion Matrix:\n",
      " [[17976   381]\n",
      " [   21  1622]]\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, X, y, name, scaled=False):\n",
    "    preds = model.predict_proba(X)[:, 1]\n",
    "    auc = roc_auc_score(y, preds)\n",
    "    print(f\"\\nðŸ”¹ {name} ROC-AUC: {auc:.4f}\")\n",
    "    print(classification_report(y, preds > 0.5, digits=4))\n",
    "    print(\"Confusion Matrix:\\n\", confusion_matrix(y, preds > 0.5))\n",
    "    return preds\n",
    "\n",
    "p_xgb = evaluate_model(xgb, X_test, y_test, \"XGBoost\")\n",
    "p_rf = evaluate_model(rf, X_test, y_test, \"RandomForest\")\n",
    "p_lr = evaluate_model(lr_model, X_test_scaled, y_test, \"LogisticRegression\", scaled=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f6aac9e-d2d2-49da-a06c-c6ed3e48d97c",
   "metadata": {},
   "source": [
    "### Train Unsupervised Isolation Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0b20ad78-73a4-4f1c-acf0-ff6338603401",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "IsolationForest trained and anomaly scores normalized.\n"
     ]
    }
   ],
   "source": [
    "iso_train = X_train[y_train == 0]  # only normal\n",
    "iso_model = IsolationForest(contamination=0.02, random_state=RANDOM_STATE)\n",
    "iso_model.fit(iso_train)\n",
    "\n",
    "# Generate anomaly scores (negative scores = anomalies)\n",
    "s_iso = -iso_model.score_samples(X_test)\n",
    "scaler_iso = MinMaxScaler()\n",
    "p_iso = scaler_iso.fit_transform(s_iso.reshape(-1, 1)).ravel()\n",
    "\n",
    "print(\"IsolationForest trained and anomaly scores normalized.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd53c592-b520-4736-a98a-c6dd1d9645f8",
   "metadata": {},
   "source": [
    "### Train Autoencoder (Unsupervised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "bcab367e-927c-494d-8e9c-58eb942e0de7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Autoencoder trained and reconstruction errors normalized.\n"
     ]
    }
   ],
   "source": [
    "# Ensure data is numeric only\n",
    "X_train_clean = X_train.select_dtypes(include=[np.number]).fillna(0)\n",
    "X_test_clean = X_test.select_dtypes(include=[np.number]).fillna(0)\n",
    "\n",
    "# Train only on non-fraud (normal) data\n",
    "ae_train = X_train_clean[y_train == 0].values.astype(\"float32\")\n",
    "input_dim = ae_train.shape[1]\n",
    "encoding_dim = int(input_dim / 2)\n",
    "\n",
    "# Build simple symmetric autoencoder\n",
    "input_layer = Input(shape=(input_dim,))\n",
    "encoder = Dense(encoding_dim, activation=\"relu\")(input_layer)\n",
    "decoder = Dense(input_dim, activation=\"sigmoid\")(encoder)\n",
    "autoencoder = Model(inputs=input_layer, outputs=decoder)\n",
    "\n",
    "# Compile and train\n",
    "autoencoder.compile(optimizer=Adam(learning_rate=0.001), loss=\"mse\")\n",
    "autoencoder.fit(ae_train, ae_train, epochs=10, batch_size=256, shuffle=True, verbose=0)\n",
    "\n",
    "#  Predict and compute reconstruction error\n",
    "X_test_np = X_test_clean.values.astype(\"float32\")\n",
    "reconstructions = autoencoder.predict(X_test_np, verbose=0)\n",
    "reconstruction_error = np.mean(np.square(X_test_np - reconstructions), axis=1)\n",
    "\n",
    "# Normalize reconstruction errors to [0,1]\n",
    "scaler_ae = MinMaxScaler()\n",
    "p_ae = scaler_ae.fit_transform(reconstruction_error.reshape(-1, 1)).ravel()\n",
    "\n",
    "print(\" Autoencoder trained and reconstruction errors normalized.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc4407fb-792b-4c8f-a5ca-5cb0628b9bf0",
   "metadata": {},
   "source": [
    "### Combine Ensemble Scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3c92f69b-9ab8-4da6-8cc4-be0d055197fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Ensemble combination complete.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>p_xgb</th>\n",
       "      <th>p_rf</th>\n",
       "      <th>p_lr</th>\n",
       "      <th>p_iso</th>\n",
       "      <th>p_ae</th>\n",
       "      <th>label</th>\n",
       "      <th>p_sup</th>\n",
       "      <th>p_unsup</th>\n",
       "      <th>p_final</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.027696e-07</td>\n",
       "      <td>0.000100</td>\n",
       "      <td>9.418246e-13</td>\n",
       "      <td>0.194879</td>\n",
       "      <td>1.136089e-19</td>\n",
       "      <td>0</td>\n",
       "      <td>3.324767e-05</td>\n",
       "      <td>0.097439</td>\n",
       "      <td>0.029255</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.346717e-07</td>\n",
       "      <td>0.000267</td>\n",
       "      <td>2.789370e-03</td>\n",
       "      <td>0.037903</td>\n",
       "      <td>4.009950e-05</td>\n",
       "      <td>0</td>\n",
       "      <td>1.018744e-03</td>\n",
       "      <td>0.018972</td>\n",
       "      <td>0.006405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.373355e-07</td>\n",
       "      <td>0.000119</td>\n",
       "      <td>1.346436e-12</td>\n",
       "      <td>0.122200</td>\n",
       "      <td>3.860469e-23</td>\n",
       "      <td>0</td>\n",
       "      <td>3.974598e-05</td>\n",
       "      <td>0.061100</td>\n",
       "      <td>0.018358</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3.425734e-06</td>\n",
       "      <td>0.000042</td>\n",
       "      <td>1.545093e-12</td>\n",
       "      <td>0.080735</td>\n",
       "      <td>2.341022e-23</td>\n",
       "      <td>0</td>\n",
       "      <td>1.514802e-05</td>\n",
       "      <td>0.040367</td>\n",
       "      <td>0.012121</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.274979e-06</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.682412e-09</td>\n",
       "      <td>0.080971</td>\n",
       "      <td>3.997017e-21</td>\n",
       "      <td>0</td>\n",
       "      <td>4.262206e-07</td>\n",
       "      <td>0.040485</td>\n",
       "      <td>0.012146</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          p_xgb      p_rf          p_lr     p_iso          p_ae  label  \\\n",
       "0  1.027696e-07  0.000100  9.418246e-13  0.194879  1.136089e-19      0   \n",
       "1  1.346717e-07  0.000267  2.789370e-03  0.037903  4.009950e-05      0   \n",
       "2  2.373355e-07  0.000119  1.346436e-12  0.122200  3.860469e-23      0   \n",
       "3  3.425734e-06  0.000042  1.545093e-12  0.080735  2.341022e-23      0   \n",
       "4  1.274979e-06  0.000000  3.682412e-09  0.080971  3.997017e-21      0   \n",
       "\n",
       "          p_sup   p_unsup   p_final  \n",
       "0  3.324767e-05  0.097439  0.029255  \n",
       "1  1.018744e-03  0.018972  0.006405  \n",
       "2  3.974598e-05  0.061100  0.018358  \n",
       "3  1.514802e-05  0.040367  0.012121  \n",
       "4  4.262206e-07  0.040485  0.012146  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results_df = pd.DataFrame({\n",
    "    \"p_xgb\": p_xgb,\n",
    "    \"p_rf\": p_rf,\n",
    "    \"p_lr\": p_lr,\n",
    "    \"p_iso\": p_iso,\n",
    "    \"p_ae\": p_ae,\n",
    "    \"label\": y_test.values\n",
    "})\n",
    "\n",
    "# Weighted ensemble (you can tune weights)\n",
    "results_df[\"p_sup\"] = results_df[[\"p_xgb\", \"p_rf\", \"p_lr\"]].mean(axis=1)\n",
    "results_df[\"p_unsup\"] = results_df[[\"p_iso\", \"p_ae\"]].mean(axis=1)\n",
    "results_df[\"p_final\"] = (0.7 * results_df[\"p_sup\"]) + (0.3 * results_df[\"p_unsup\"])\n",
    "\n",
    "print(\" Ensemble combination complete.\")\n",
    "results_df.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2ca13e4-7380-4103-941e-5b8bd2f47b23",
   "metadata": {},
   "source": [
    "### Risk Buckets & Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4feb1b72-ebce-48ba-babd-785fada5f492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Risk buckets generated:\n",
      "risk_bucket\n",
      "Low       18328\n",
      "High       1596\n",
      "Medium       76\n",
      "Name: count, dtype: int64\n",
      "\n",
      " Final Ensemble ROC-AUC: 0.9996\n"
     ]
    }
   ],
   "source": [
    "def risk_bucket(p):\n",
    "    if p >= 0.7:\n",
    "        return \"High\"\n",
    "    elif p >= 0.3:\n",
    "        return \"Medium\"\n",
    "    return \"Low\"\n",
    "\n",
    "results_df[\"risk_bucket\"] = results_df[\"p_final\"].apply(risk_bucket)\n",
    "print(\" Risk buckets generated:\")\n",
    "print(results_df[\"risk_bucket\"].value_counts())\n",
    "\n",
    "roc_final = roc_auc_score(results_df[\"label\"], results_df[\"p_final\"])\n",
    "print(f\"\\n Final Ensemble ROC-AUC: {roc_final:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9daa81e2-e18e-45a6-850f-a2af7a422438",
   "metadata": {},
   "source": [
    "### Save All Models "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "447bdca9-7a1f-430d-b269-430c9146ffb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble models and results saved in: ../models/upi_ensemble\n"
     ]
    }
   ],
   "source": [
    "model_dir = \"../models/upi_ensemble\"\n",
    "os.makedirs(model_dir, exist_ok=True)\n",
    "\n",
    "joblib.dump(xgb, f\"{model_dir}/xgb_best.joblib\")\n",
    "joblib.dump(rf, f\"{model_dir}/rf_best.joblib\")\n",
    "joblib.dump(lr_model, f\"{model_dir}/lr_best.joblib\")\n",
    "joblib.dump(iso_model, f\"{model_dir}/iso_model.joblib\")\n",
    "autoencoder.save(f\"{model_dir}/autoencoder.keras\")\n",
    "joblib.dump(scaler, f\"{model_dir}/scaler_lr.joblib\")\n",
    "joblib.dump(scaler_iso, f\"{model_dir}/scaler_iso.joblib\")\n",
    "joblib.dump(scaler_ae, f\"{model_dir}/scaler_ae.joblib\")\n",
    "\n",
    "results_df.to_csv(\"../dataset/upi_ensemble_predictions.csv\", index=False)\n",
    "print(f\"Ensemble models and results saved in: {model_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c37389a-2b21-48dd-9f6d-1a92a6dca589",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (tf_env)",
   "language": "python",
   "name": "tf_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
